# -*- coding: utf-8 -*-
"""chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Le3ZjNO26_T1ve40CS9-LGcM3zpPD9YJ
"""

import os
import nltk
import ssl
import streamlit as st
import random
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

ssl._create_default_https_context=ssl._create_unverified_context
nltk.data.path.append(os.path.abspath("nltk_data"))
nltk.download('punkt')

pip install nltk

pip install scikit-learn

import json

# Load JSON data
with open(r'C:\Users\baska\Downloads\SIH\chatbot\intents.json', 'r') as file:
    data = json.load(file)

# Print the loaded data to verify its structure
print(type(data))  # Should print <class 'dict'>
print(data.keys())  # Should show keys like 'intents'

# Check the structure inside 'intents'
print(type(data['intents']))  # Should print <class 'list'>
print(data['intents'][0])  # Should show the first intent with keys like 'tag', 'patterns', 'responses'

#vectorizer
vectorizer=TfidfVectorizer()
clf=LogisticRegression(random_state=0,max_iter=10000)

# Assuming 'data' is the dictionary containing the JSON data
intents = data['intents']  # Extract the list of intents

tags = []
patterns = []

# Iterate through each intent in the list
for intent in intents:
    for pattern in intent['patterns']:
        tags.append(intent['tag'])
        patterns.append(pattern)

# Print the results to verify
print("Tags:", tags)
print("Patterns:", patterns)

#train
x=vectorizer.fit_transform(patterns)
y=tags
clf.fit(x,y)

#create chatbot

def chatbot(input_text):
    input_text=vectorizer.transform([input_text])
    tag=clf.predict(input_text)[0]
    for intent in intents:
        if intent['tag']==tag:
            response=random.choice(intent['responses'])
            return response

